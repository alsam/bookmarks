+ Michael Jordan
    + [Искусственный интеллект, большие данные и дезинформация технологий: интервью профессора Беркли](http://habrahabr.ru/company/1cloud/blog/258219/)
        + [AMA: Michael I Jordan](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)
        + [Big Data, Hype, the Media and Other Provocative Words to Put in a Title](https://amplab.cs.berkeley.edu/big-data-hype-the-media-and-other-provocative-words-to-put-in-a-title/)
        + [a goodreads list of books for ML](https://www.goodreads.com/review/list/6324945-nikita-zhiltsov?shelf=m-jordan-s-list)

+ [SETTING UP EOS FREYA AND ANACONDA ON A HYBRID GRAPHICS LAPTOP FOR GPU ACCELERATED DEEP LEARNING](https://wolfchimneyrock.wordpress.com/2015/05/25/eos-cuda/)

+ Deeplearning4J: Spark + GPU
    + [Deeplearning4J is an Apache2 Licensed open-sourced, distributed neural net library written in Java and Scala.](https://github.com/deeplearning4j)
        + [Deeplearning4J: Neural Net Platform](https://github.com/deeplearning4j/deeplearning4j)
        + [spark-gpu-examples](https://github.com/deeplearning4j/spark-gpu-examples)
        + [Scientific Computing for the JVM (NDArrays)](https://github.com/deeplearning4j/nd4j)
            + [ND4J: N-Dimensional Arrays for Java](http://nd4j.org/)

+ Recurrent Neural Networks
    + [Supervised Sequence Labelling with Recurrent Neural Networks](http://www6.in.tum.de/Main/Publications/Graves2008c.pdf)
    + [Alex Graves](http://www.cs.toronto.edu/~graves/)

+ Deep Learning
    + [Deep Learning: Methods and Applications](http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf)

+ Nervana Systems
    + [Nervana](http://www.nervanasys.com/)
        + [github repo for Nervana Systems](https://github.com/NervanaSystems)
    + [Nervana's python based Deep Learning Framework http://neon.nervanasys.com/](https://github.com/NervanaSystems/neon)
    + [NervanaSystems/nervanagpu: Nervana GPU library](https://github.com/NervanaSystems/nervanagpu)
    + [custom form of cuda-convnet2](https://github.com/NervanaSystems/cuda-convnet2)
        + [original cuda-convnet2](https://code.google.com/p/cuda-convnet2/)
    + [Assembler for NVIDIA Maxwell architecture](https://github.com/NervanaSystems/maxas)
        + [open source reverse engineering of Maxwell scheduler hints](https://github.com/NervanaSystems/maxas/wiki/Control-Codes)

+ Misc
    + [https://medium.com/deep-learning-101/how-to-create-a-mind-the-secret-of-human-thought-revealed-6211bbdb092a](https://medium.com/deep-learning-101/how-to-create-a-mind-the-secret-of-human-thought-revealed-6211bbdb092a)

    + [colah's blog](http://colah.github.io/archive.html)
        + [https://christopherolah.wordpress.com/](https://christopherolah.wordpress.com/)
        + [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs)
        + [Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/index.html)
            + [Stalingrad Home Page](http://www.bcl.hamilton.ie/~qobi/stalingrad/)
                + [dysvunctional-language](https://github.com/axch/dysvunctional-language)
        + [Deep Learning, NLP, and Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)
        + [Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)
        + [Understanding Convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)


    + [Andrej Karpathy blog](http://karpathy.github.io/)
        + [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
            + [Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch ](https://github.com/karpathy/char-rnn)
                + [Torch is a scientific computing framework with wide support for machine learning algorithms](http://torch.ch/)
                    + [torch/torch7](https://github.com/torch/torch7)
                    + [Torch Cheatsheet](https://github.com/torch/torch7/wiki/Cheatsheet#cuda)
                    + [Learn Lua in 15 Minutes](http://tylerneylon.com/a/learn-lua/)

    + [A curated list of speech and natural language processing resources](https://medium.com/@joshdotai/a-curated-list-of-speech-and-natural-language-processing-resources-4d89f94c032a#.2cyphikgy)

    + RNN et. al
        + [Optimizing RNN performance : Part I: Investigating performance of GPU BLAS Libraries](http://svail.github.io/)
        + [MemN2N for language modeling](https://github.com/facebook/MemNN/tree/master/MemN2N-lang-model)
        + [Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)
        + [Recurrent Neural Networks Tutorial, Part 2 – Implementing a RNN with Python, Numpy and Theano](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/)
        + [Recurrent Neural Networks Tutorial, Part 3 – Backpropagation Through Time and Vanishing Gradients](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)
        + [Top 5 arXiv Deep Learning Papers, Explained](http://www.kdnuggets.com/2015/10/top-arxiv-deep-learning-papers-explained.html)
        + [thesis: Reinforcement Learning with Recurrent Neural Networks](https://repositorium.uni-osnabrueck.de/bitstream/urn:nbn:de:gbv:700-2008112111/2/E-Diss839_thesis.pdf)

        + [Demystifying LSTM neural networks](http://blog.terminal.com/demistifying-long-short-term-memory-lstm-recurrent-neural-networks/)
        + [A Critical Review of Recurrent Neural Networks for Sequence Learning](http://arxiv.org/pdf/1506.00019v4.pdf)

        + [Minimal, clean example of lstm neural network training in python, for learning purposes](https://github.com/nicodjimenez/lstm)

    + misc.
        + [Model-Based Machine Learning, Free Early Book Draft](http://www.rightrelevance.com/search/articles/hero?article=f8f357759d3967360b016af629853d8d27850ffa&query=machine%20learning&taccount=ml_toparticles)
        + [Recent Advances in Face Recognition](http://www.face-rec.org/journals-books/Delac_Grgic_Bartlett_Recent_Advances_in_Face_Recognition.pdf)
        + [An Introduction to Machine Learning Theory and Its Applications: A Visual Tutorial with Examples](http://www.datasciencecentral.com/profiles/blogs/an-introduction-to-machine-learning-theory-and-its-applications-a)
            + [An Introduction to Machine Learning Theory and Its Applications: A Visual Tutorial with Examples](http://www.rightrelevance.com/search/articles/hero?article=d48a3b36a554c8385c643978b44a1a413516a3cc&query=machine%20learning&taccount=ml_toparticles)
        + [An Algorithmic God -- Gregory Chaitin](http://inference-review.com/article/an-algorithmic-god)

        + [Homomorphic machine learning; in Haskell](https://github.com/mikeizbicki/HLearn)
            + [Mike Izbicki' blog](https://izbicki.me/)
